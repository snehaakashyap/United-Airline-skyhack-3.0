{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMoKLKp1yQrFSfbUXz+4KbX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["FLIGHT DELAY SCORE GENERATOR"],"metadata":{"id":"3MScCxImDhqh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VwwqpkO7C_Au"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","\n","def calculate_flight_difficulty_score(flight_data_path, bag_data_path, pnr_flight_data_path, pnr_remark_data_path,\n","                                      use_random_conn_time=True, difficult_q=0.8, easy_q=0.2):\n","\n","    # Step 1: Load data\n","    df_flights = pd.read_csv(flight_data_path)\n","    df_bags = pd.read_csv(bag_data_path)\n","    df_pnr = pd.read_csv(pnr_flight_data_path)\n","    df_remarks = pd.read_csv(pnr_remark_data_path)\n","\n","    dep_dt = pd.to_datetime(df_flights.get('scheduled_departure_datetime_local', pd.NaT), errors='coerce')\n","    df_flights['departure_hour'] = dep_dt.dt.hour\n","\n","\n","    # Step 2: Fix remarks with date by merging with PNR lookup\n","    pnr_lookup = df_pnr[['record_locator', 'flight_number', 'scheduled_departure_date_local']].drop_duplicates()\n","    df_remarks_with_date = pd.merge(\n","        df_remarks, pnr_lookup, on=['record_locator', 'flight_number'], how='left'\n","    )\n","\n","\n","    # Step 3: Aggregate bag data\n","    df_bags = df_bags.copy()\n","    if use_random_conn_time:\n","        np.random.seed(42)\n","        transfer_idx = df_bags.index[df_bags['bag_type'] == 'Transfer']\n","        df_bags.loc[transfer_idx, 'connection_time'] = np.random.randint(10, 120, size=len(transfer_idx))\n","\n","\n","    df_bags['is_hot_transfer'] = (df_bags['bag_type'] == 'Transfer') & (df_bags['connection_time'] < 30)\n","    df_bags['is_other_transfer'] = (df_bags['bag_type'] == 'Transfer') & (df_bags['connection_time'] >= 30)\n","\n","\n","    bag_counts = df_bags.groupby(['flight_number', 'scheduled_departure_date_local']).agg(\n","        total_checked_bags=('bag_tag_unique_number', 'count'),\n","        hot_transfer_bags=('is_hot_transfer', 'sum'),\n","        other_transfer_bags=('is_other_transfer', 'sum')\n","    ).reset_index()\n","\n","\n","    # Step 4: Aggregate PNR and SSR data\n","    pnr_counts = df_pnr.groupby(['flight_number', 'scheduled_departure_date_local']) \\\n","                       .agg(total_pax=('total_pax', 'sum')).reset_index()\n","\n","\n","    ssr_counts = df_remarks_with_date.groupby(['flight_number', 'scheduled_departure_date_local']) \\\n","                                     .agg(ssr_count=('special_service_request', 'count')).reset_index()\n","\n","\n","    # Step 5: Merge to flight level\n","    merge_keys = ['flight_number', 'scheduled_departure_date_local']\n","    df = pd.merge(df_flights, bag_counts, on=merge_keys, how='left')\n","    df = pd.merge(df, pnr_counts, on=merge_keys, how='left')\n","    df = pd.merge(df, ssr_counts, on=merge_keys, how='left')\n","\n","\n","    # Fill missing aggregates\n","    for col in ['total_checked_bags', 'hot_transfer_bags', 'other_transfer_bags', 'total_pax', 'ssr_count']:\n","        if col in df.columns:\n","            df[col] = df[col].fillna(0)\n","\n","\n","    # Step 6: Feature engineering\n","    # Turn pressure: smaller or negative scheduled ground time vs minimum implies pressure; invert sign to keep higher worse\n","    df['turnaround_pressure'] = df['minimum_turn_minutes'] - df['scheduled_ground_time_minutes']\n","\n","\n","    # Bag complexity\n","    df['baggage_complexity_score'] = (df['hot_transfer_bags'] * 2) + df['other_transfer_bags']\n","\n","\n","    # Passenger service load\n","    df['passenger_service_load'] = df['ssr_count']\n","\n","\n","    # Congestion factor: robust to missing hours\n","    # Map hour bins to 1..4; any NaN hour gets the lowest congestion 1 (or choose a neutral 2)\n","    bins = [0, 9, 15, 20, 24]\n","    labels = [1, 2, 3, 4]\n","    valid_hours = df['departure_hour'].between(0, 23, inclusive='both')\n","    df.loc[valid_hours, 'congestion_factor'] = pd.cut(\n","        df.loc[valid_hours, 'departure_hour'],\n","        bins=bins, labels=labels, right=False, include_lowest=True\n","    ).astype('Int64')\n","    df['congestion_factor'] = df['congestion_factor'].fillna(1).astype(int)\n","\n","\n","    # Route difficulty\n","    df['route_difficulty_flag'] = df['scheduled_arrival_station_code'].isin(['ASE', 'GRU', 'JLN', 'FAT', 'LHR']).astype(int)\n","\n","\n","    # Total volume\n","    df['total_volume'] = df['total_pax'] + df['total_checked_bags']\n","\n","\n","    # Step 7: Daily normalization, scoring, ranking, classification\n","    features_to_normalize = [\n","        'turnaround_pressure', 'baggage_complexity_score', 'congestion_factor',\n","        'passenger_service_load', 'route_difficulty_flag', 'total_volume'\n","    ]\n","\n","\n","    def normalize_group(g):\n","        for f in features_to_normalize:\n","            min_v = g[f].min()\n","            max_v = g[f].max()\n","            if pd.isna(min_v) or pd.isna(max_v) or max_v == min_v:\n","                g[f'norm_{f}'] = 0.0\n","            else:\n","                g[f'norm_{f}'] = (g[f] - min_v) / (max_v - min_v)\n","        # Weighted score\n","        g['difficulty_score'] = (\n","            0.30 * g['norm_turnaround_pressure'] +\n","            0.25 * g['norm_baggage_complexity_score'] +\n","            0.15 * g['norm_congestion_factor'] +\n","            0.15 * g['norm_passenger_service_load'] +\n","            0.10 * g['norm_route_difficulty_flag'] +\n","            0.05 * g['norm_total_volume']\n","        )\n","        # Rank within day (1 = hardest)\n","        g['daily_rank'] = g['difficulty_score'].rank(method='dense', ascending=False).astype(int)\n","        # Quantile-based classification on scores to approximate 20/60/20 by flight count\n","        if len(g) >= 5:\n","            low_thr = g['difficulty_score'].quantile(easy_q)\n","            high_thr = g['difficulty_score'].quantile(difficult_q)\n","            g['difficulty_category'] = np.select(\n","                [g['difficulty_score'] >= high_thr, g['difficulty_score'] <= low_thr],\n","                ['Difficult', 'Easy'],\n","                default='Medium'\n","            )\n","        else:\n","            # Fallback for very small days: rank-based 1-2 hardest as Difficult, last 1-2 as Easy\n","            max_rank = g['daily_rank'].max()\n","            g['difficulty_category'] = np.where(\n","                g['daily_rank'] <= max(1, round(0.2 * max_rank)),\n","                'Difficult',\n","                np.where(\n","                    g['daily_rank'] >= max_rank - max(0, round(0.2 * max_rank) - 1),\n","                    'Easy',\n","                    'Medium'\n","                )\n","            )\n","        return g\n","\n","\n","    final_df = df.groupby('scheduled_departure_date_local', group_keys=False).apply(normalize_group)\n","\n","\n","    # Step 8: Output selection (include available identifiers only)\n","    desired_cols = [\n","        'company_id', 'flight_number', 'scheduled_departure_date_local',\n","        'scheduled_departure_station_code', 'scheduled_arrival_station_code',\n","        'turnaround_pressure', 'baggage_complexity_score', 'congestion_factor',\n","        'passenger_service_load', 'route_difficulty_flag', 'total_volume',\n","        'difficulty_score', 'daily_rank', 'difficulty_category'\n","    ]\n","    output_cols = [c for c in desired_cols if c in final_df.columns]\n","\n","    # Post-sort by category (Difficult > Medium > Easy) and then by daily_rank, preserving tie order\n","    if 'difficulty_category' in final_df.columns and 'daily_rank' in final_df.columns:\n","        cat_order = pd.CategoricalDtype(categories=['Difficult', 'Medium', 'Easy'], ordered=True)\n","        final_df['_cat_key'] = final_df['difficulty_category'].astype(cat_order)\n","        final_df = final_df.sort_values(by=['_cat_key', 'daily_rank'], ascending=[True, True], kind='mergesort')\n","        final_df = final_df.drop(columns=['_cat_key'])\n","\n","    return final_df[output_cols].reset_index(drop=True)\n","\n","\n","\n","\n","if __name__ == '__main__':\n","    FLIGHT_DATA_PATH = '/content/Flight Level Data.csv'\n","    BAG_DATA_PATH = '/content/Bag Level Data.csv'\n","    PNR_FLIGHT_PATH = '/content/PNR Flight Level Data.csv'\n","    PNR_REMARK_PATH = '/content/PNR Remark Level Data.csv'\n","\n","\n","    submission_df = calculate_flight_difficulty_score(\n","        FLIGHT_DATA_PATH, BAG_DATA_PATH, PNR_FLIGHT_PATH, PNR_REMARK_PATH,\n","        use_random_conn_time=True, difficult_q=0.8, easy_q=0.2\n","    )\n","    YOUR_NAME = 'United_Together'\n","    output_filename = f'test_{YOUR_NAME}.csv'\n","    submission_df.to_csv(output_filename, index=False)\n","    print(f\"Successfully generated submission file: {output_filename}\")\n"]}]}